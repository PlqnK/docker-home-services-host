---
- name: 'Check if provisioning a Vagrant VM'
  ansible.builtin.getent:
    database: 'passwd'
    key: 'vagrant'
    fail_key: false

- name: 'Manage Overseerr CNAME record'
  when: (getent_passwd.vagrant is none)
  delegate_to: 'localhost'
  block:
    - name: 'Get Overseerr CNAME record'
      ansible.builtin.uri:
        url: 'https://desec.io/api/v1/domains/{{ domain_name }}/rrsets/overseerr/CNAME/'
        method: 'GET'
        status_code: [200, 404]
        headers:
          Authorization: 'Token {{ desec_token }}'
      register: desec_rrsets_get

    - name: 'Create Overseerr CNAME record'
      ansible.builtin.uri:
        url: 'https://desec.io/api/v1/domains/{{ domain_name }}/rrsets/'
        method: 'POST'
        status_code: [201]
        headers:
          Authorization: 'Token {{ desec_token }}'
        body_format: 'json'
        body:
          subname: 'overseerr'
          type: 'CNAME'
          ttl: 3600
          records:
            - '{{ ansible_fqdn }}.'
      register: desec_rrsets_post
      when: (desec_rrsets_get.status == 404)
      changed_when: (desec_rrsets_post.status == 201)

    - name: 'Update Overseerr CNAME record'
      ansible.builtin.uri:
        url: 'https://desec.io/api/v1/domains/{{ domain_name }}/rrsets/overseerr/CNAME/'
        method: 'PATCH'
        status_code: [200]
        headers:
          Authorization: 'Token {{ desec_token }}'
        body_format: 'json'
        body:
          records:
            - '{{ ansible_fqdn }}.'
      register: desec_rrsets_patch
      when: (desec_rrsets_get.status == 200 and desec_rrsets_get.json.records != ["{{ ansible_fqdn }}."])
      changed_when: (desec_rrsets_patch.status == 200)

- name: 'Create Overseerr data bind mount path'
  ansible.builtin.file:
    path: '{{ containers_storage_path }}/data/overseerr'
    owner: 'root'
    group: 'root'
    mode: '0700'
    state: 'directory'

- name: 'Create Overseerr container'
  containers.podman.podman_container:
    name: 'overseerr'
    image: '{{ containers_images.overseerr }}:{{ containers_images_tags.overseerr }}'
    network:
      - 'web-egress'
      - 'common-internal'
    expose:
      - 5055
    volume:
      - '{{ containers_storage_path }}/data/overseerr:/app/config:Z'
    timezone: '{{ timezone }}'
    env:
      TZ: '{{ timezone }}'
    label:
      traefik.enable: 'true'
      traefik.docker.network: 'common-internal'
      traefik.http.routers.overseerr.rule: 'Host(`overseerr.{{ domain_name }}`)'
      traefik.http.routers.overseerr.entrypoints: 'websecure'
      traefik.http.routers.overseerr.middlewares: 'set-security-headers@file'
      traefik.http.services.overseerr.loadbalancer.server.port: '5055'
    generate_systemd:
      names: true
      new: true
      path: '/etc/systemd/system'
      restart_policy: 'on-failure'
    state: 'created'

- name: 'Enable and start Overseerr container'
  ansible.builtin.systemd:
    name: 'container-overseerr.service'
    daemon_reload: true
    enabled: true
    state: 'started'
